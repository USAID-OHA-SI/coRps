---
title: "transform_data"
author: "jdavis"
date: "4/27/2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting started
Today we're going to get into the down and dirty with one of the more valuable packages in the tidyverse, `dplyr`. Simply put, `dplyr` implements a grammar for transforming tabular data. It is powerful and has a number of wide ranging functions and uses, that will no doubt inspire joy, adminiration, fear, and dread (in somewhat equal measures) as you advance through your learning of `R`

We've touched on the use of `dplyr` in the previous exercises invovlving `ggplot`, but today we will go into some detail as to what those functions are doing and the different ways we can use them in our work.


  load r packages and import data
```{r message=FALSE}

library(tidyverse)
library(ICPIutilities)

dataset_url <- "https://raw.githubusercontent.com/USAID-OHA-SI/coRps/master/2020-04-27/dplyr_exercise.csv"

df <- read_csv(dataset_url)

```


Let's take a look at all the packages loaded with `install.packages("tidyverse")`, which actually installs a host of packages for you to use. We can see what those are through running the code below.

```{r tidyverse}
tidyverse::tidyverse_packages()
```

Another interesting exercise is to look at the bounty of functions available in `dplyr`. You can see there are 267, but today we'll only be focusing on 4 time permitting; `filter`, `mutate`, `rename`, and `select`. One of the great things about the tidyverse in general, and dplyr in specific is the strength and flexilibity of the 'helpers' that are able to used with each function. These helpers are extremely valuable for expanding what can be done with these functions, often allowing you to `pipe ( %>% )` together multiple transformation actions into easy to manage and intrepret code chunks. This comes in handy when you have a lot of transformations to make, or as we saw with the `ggplot2` section, the transformation is not the end goal in and of itself. 

```{r}

ls(package:dplyr)

```

## dplry::filter

`filter` extracts rows that meet a logical criteria
Like most of the tidyverse, `filter` follows a predicatable syntax
`filter`(data_to_transform, condition)
So we're going to spend a little bit of time going over the basics and then get into some of the ways to modify `filter`

```{r}
## as always lets have a look at our data
glimpse(df)

##which OUs are we dealing with?
distinct(df, operatingunit)

df %>% distinct(operatingunit)

##if we want to limit our analysis to just Saturn
df %>% 
filter(operatingunit == "Saturn") %>% 
  distinct(operatingunit)

## more than one criteria?
distinct(df, indicator)

drop_me <- c("HTS_TST", "HTS_TST_POS")

df %>% 
  filter(indicator %in% c("HTS_TST", "HTS_TST_POS")) %>% 
  distinct(indicator)


## this works with 'everything but' which can be helpful
## !%in% might seem logic but it won’t work.

distinct(df, psnu)

## remove Thea and Mimas

df %>%
  filter(!psnu %in% c("Thea", "Mimas")) %>% 
  distinct(psnu)

df %>% 
  filter(psnu == "Dione" | psnu == "Europa" | psnu == "Ganymede") %>% 
  distinct(psnu)

##  you can also use logical tests with filter
##  >, >=, <, <=, == and != (plus %in% (group membership) which we just did)

df %>% 
  filter(!is.na(cumulative)) %>% 
  glimpse()

df %>% 
  filter(!is.na(cumulative), !is.na(targets)) %>% 
  glimpse()



## Can take boolean operators, with some caveats
## filter out the missing values for results (helpful with DATIM data)



```

One nice aspect about working in the tidyverse is that you can write your code in a nice, organized way. You can 'stack' your conditions within the same function for ease of reading. This helps when you want to go back and quickly tell if you munged the data the way you meant to. Using the `space` and `tab` keys in rstudio makes for uniform indentions

```{r}

## subset down to just one indicator for one time period for one partner
## TX_CURR, for mech "AlfMr" for psnu Ganymede

df %>% 
  filter(indicator == "TX_CURR") %>% 
  filter(mech_name == "AlfMr") %>% 
  filter(psnu == "Ganymede") %>% 
  glimpse()

df %>% 
  filter(indicator == "TX_CURR",
         mech_name == "AlfMr",
         psnu == "Ganymede") %>% 
  glimpse()

## create a list of what you want to filter and play with that
## a set of mechs perhaps

things_to_keep <- c("Ssr", "RjllAww", "Askll", "AsllusSrus")

df %>%
  filter(mech_name %in% things_to_keep) %>% 
  distinct(mech_name)

```

So we've covered how to filter within one or more variables, now we're going to introduce one of the variants of `filter`, which is `filter_at`. Several of the `dplyr` functions have variant suffixes (`_at`, `_if`, `_all`) that allow you to apply the same condition across multiple colums at once. This means you can do with one line what might have taken several. We're also going to start playing with a couple of the ways to define your logical condition `contains()`, `starts_with()`, and `ends_with()`.

let's try with `filter_at`
`filter_at` takes two arguements `vars`, a function where you specifiy the vars you are filtering on &
`all_vars()` or `any_vars`. `all_vars()` is the intersection (`&`) and `any_vars`() is the union (`|`)



```{r}

## lets look at where the value for cumulative and targets is over 100
df %>% 
  filter(targets > 100 & cumulative >100) %>% 
  glimpse()

##using filter_at

df %>% 
  filter_at(vars(targets, cumulative), all_vars(. >100)) %>% 
  glimpse()

df %>% 
  filter(., operatingunit == "Saturn") %>% 
  glimpse()

```

Because of reasons, there are a lot of 0 values in the DATIM data. Depending on what we're trying to do, this can cause problems. Sometimes we're only interested in the total or `cumulative` value for a particular `fiscal_year`, but often times we want to look at trends, quarter over quarter. Part of making the initial munging you do on an MSD should be to make your `df` as small as possible. This will serve you well; what you end up doing with it (tableau, excel, whatever) might not be apparant when you first start.


```{r}
#returning to our data (742 rows)

glimpse(df)

#Let's try and remove where any of the rows have no data (546 rows)
df %>%
  filter(!is.na(qtr1) | !is.na(qtr2) | !is.na(qtr3) | !is.na(qtr4)) %>% 
  glimpse()

## line 179 was kind of a pain to type out (trust me)

## try with starts_with, inside of vars()

df %>%
  filter_at(vars(starts_with("qtr")), any_vars(!is.na(.))) %>% 
  glimpse()


##also works with contains

df %>%
  filter_at(vars(contains("qtr")), any_vars(!is.na(.))) %>% 
  glimpse()


## can do this same with filter_if but it requires some modifications
df %>%
  filter_if(is.double, any_vars(!is.na(.))) %>% 
  glimpse()


df %>%
  select(-cumulative, -targets, -fiscal_year) %>% 
  filter_if(is.double, any_vars(!is.na(.))) %>% 
  glimpse()

## one way to remove all the rows with all na's

df %>%
  filter_if(is.double, any_vars(!is.na(.) & . != 0)) %>% 
  glimpse()

glimpse(df)

``` 

MUTATE
Let's create new columns!
`mutate` has an almost endless number of options, we'll try and cover a few here that we've found to be useful with PEPFAR data

One of the simplest options is a calculation based on values in other columns. In the sample code, we’re changing the sleep data from data measured in hours to minutes.

```{r}
glimpse(df)

##let's create a flag variable for non-missing fy20 targets


## what about something more useful


## make it look a little nicer


## more useful still


```

`mutate` can be used to create a new column, or replace an exsisting column by keeping the same name
Below is a really good thing to add when working with the MSD

```{r}



```

We're going to tiptoe into condtions now. There is a lot to cover so we'll start slow.
A very simple but powerful function to use with `mutate` is `if_else()`. With `if_else()`, you first specify a logical statement, afterwards what needs to happen if the statement returns TRUE, and lastly what needs to happen if it’s FALSE. ([What is the difference between ifelse() and if_else?](https://medium.com/@HollyEmblem/chaining-if-else-statements-using-the-superheroes-dataset-with-dplyr-b13121777b4))

```{r}

# let's make some groups, shall we?



## note it dropped dedups
## usaid vs others



## make it a little nicer


## let's try an example with a logical operator
## how many mechs had targets for TX_CURR for USAID in 2019?

df %>% distinct(mech_name, fundingagency, fiscal_year)
## not helpful



```




























dplyr::select
`select` extracts columns by name. 

```{r}
glimpse(df)

df %>% select(operatingunit, psnu, fundingagency, standardizeddisaggregate, fiscal_year, targets) %>% 
  glimpse()

## change the order of the vars within your select statement
df %>% select(targets, fiscal_year, operatingunit, psnu, fundingagency, standardizeddisaggregate) %>% 
  glimpse()

```

##helpers part 1 : ranges and `ends_with`
Pretty straight forward right? If you have a lot of things you want to select, it can be a pain to list everything out in a select statement, in that case there are a couple of options. 
```{r}
## use a start_col:end_col, or a range

df %>% select(operatingunit:targets) %>% 
  glimpse()

##combine ranges
df %>% select(operatingunit:fundingagency, standardizeddisaggregate:targets)

##you can also deselect columns by adding a - in front of them : note use of parans
df %>% select(-region, -regionuid, -(snuprioritization:disaggregate))

## you can even deselect a chunk and re-add a column
df %>% select(-(snuprioritization:modality), standardizeddisaggregate, indicator) %>% 
  glimpse()

## if you have data that has column names of a similar struture, you can use partial matching
df %>% select(operatingunit, ends_with("uid")) %>%
  glimpse()

## cool, but not very helpful, we really want to do the reverse
df %>% select(-ends_with("uid")) %>% 
  glimpse()

```

## select_if
```{r}
#to do

```

## rename and rename_all
Next, we're going to talk about how to rename columns. This is really easy with `dplyr` and useful when working with the MSD as a lot of times you'll want to rename the vars in your df for display/viz purposes. We're all introducing the `_all` modifier for the dplyr functions here. Note that these are not helpers, they are standalone functions, just that the role they serve is a lot like the helpers. `rename` is pretty straightforward: `rename(new_name = old_name)` (note, if you are like me you will get that backwards a seemingly unbelievable number of times)
```{r}

df <- df %>% 
  rename()



```


##helpers part 2 : contains, starts_with, ends_with
This is where the helpers start to get neat, `dplyr` if you have a lot of columns with similar structure you can use some of partial matching to choose what you want.
```{r}
df %>% select()

```










##running list of helpers for the facilitation team to help josh figure out where to include
```{r}
one_col:another_col (range)
-c("one_col", "another_col") (except)
starts_with()
ends_with()
contains()
matches()
one_of()
## boolean
<
>
==
<=
>=
!=
%in%
is.na()
!is.na()




```






















