---
title: "import_merge_append"
author: "G. Sarfaty | B. Kagniniwa"
date: "5/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting Started

We started with the fun stuff, like visualizing and transforming data! :) 
Now we are on to importing, merging, and appending data from multiple sources


## Install Packages

In a previous session, you saw how to install additional packages that are not available on CRAN, like [ICPIutilities](https://github.com/ICPI/ICPIutilities/blob/master/README.md) which is package developed for use with the PEPFAR MSD. It can be installed from GitHub (via the `devtools` package). If you don't have it installed yet, you can run the code below to do so.


```{r install_github}
#install ICPI utilities using devtools
devtools::install_github("ICPI/ICPIutilities")

```

There are other useful packages to improve your productivity

1. here
The package here will help you find your files

```{r echo=FALSE}
install.packages("here")
```

2. glamr
This package is a sister package of ICPIutilities for working with data from datim and the MER
The main function that we will be introducing today is glamr::folder_setup()

```{install_github}
install.packages("devtools")
devtools::install_github("USAID-OHA-SI/glamr")
```

## Load Packages
Now we will load the packages we want to use.

```{r load, echo=FALSE}
library(tidyverse)
library(readxl)
library(here)
library(ICPIutilities)
library(glamr)
```


## Importing data

Today, we will walk through how to load data in R with the 'readr' package which is part of tidyverse. For the most part, 'readr' functions handle converting flat files to data frames. The most common are read_csv (comma separated values), read_tsv (tab delimited), read_delim (any delimiter). Once you know the syntax of one of these, generally, you can apply it the same way to the others.

First, we are going to look at a data set from the United Nations & troubleshoot the import process using read_csv!

Import UN data set from URL

```{r}
dataset_url <- "https://data.un.org/_Docs/SYB/CSV/SYB62_1_201907_Population,%20Surface%20Area%20and%20Density.csv"
```

```{r}
un_pop <- read_csv(dataset_url)
```


Inspect your dataset - what do you notice?

```{r}



```



How can we fix it to read in correctly?

```{r}
un_pop <- read_csv(dataset_url,
                   
```


Look at the new import to see the difference

```{r}


```


Close - but one column was missing a name - anyone remember how we can rename a column (X2)?

```{r}
un_pop <- un_pop %>% 
 
  
```


Check and see if we did it correctly

```{r}


```


We may also want to specify how missing values are represented in our file. Let's pretend missing values are noted as 2005

```{r}
un_pop <- read_csv(dataset_url, 
                   
```


Notice how the columns were read in - R guessed what the columns were based on the 1st 1000 rows

```{r}


```


How do we fix that if it guessed wrong? we can specify column type on import

```{r}
un_pop <- read_csv(dataset_url, 
                   


```

Remember ICPI Utilities? you can use it to read MSDs and it will pick correct column type for you

```{r}
msd_url <- "https://raw.githubusercontent.com/USAID-OHA-SI/coRps/master/2020-05-29/MSD_Training_subset_Saturn_PSNU_IM_FY18-20_20200214_v1_1.txt"
```

Let's take advantage to read_msd function from from ICPIUtilities packages

```{r}
msd <- 
  
  
```
Inspect the content of the file

```{r}
glimpse(msd)

```

But what about Excel files? We receive many of those from various stakeholders. It's no problem for R. Now we will read in an excel file using the 'readxl' package which is also part of the tidyverse.Go ahead and clear your workspace since we will no longer be using the UN dataset.

```{r}
#read xlsx - specify path, sheet name to read, rows to skip

df <- read_xlsx("HIV_estimates_from_1990-to-present.xlsx", 
                

```

We could also take advantage of here package to identify the file full path

```{r}
# Get the current working directory.
# There function is similar to getwd()
here()
getwd()
```

What's the full path of our excel file?
Notice how here combines all components and create a full path

```{r}
here("HIV_estimates_from_1990-to-present.xlsx")

```

Here is very useful where you have multiple folders in your projects
A quick way to create some of the most commonly used folders is to user folder_setup function from glamr

```{r}
glamr::folder_setup()
```


folder_setup has a default list of folders: "Data", "Images", "Scripts", "Dataout", "GIS", "Documents", "Graphics", "markdown"
You can always overrite this list with folder_list arguments

```{r}
glamr::folder_setup(folder_list = list("COVID", "TWG"))
```


Let's try to read the content of the excel file again, this time using 2020-05-29 as my top level directory, with the HIV estimates file stored in a subfolder called "Data"

```{r}
df <- read_xlsx(
  
  
  
```


``` {r}
#inspect
glimpse(df)
```

Note: we could have used an index to identify the excel tab you are interested in


There is a quick way of taking a peek at excel file content
Let's list out the names of all tabs in this file

```{r}
excel_sheets(
  
```


Could we read the content of all these tabs simultaneously?

```{r}
path <- here("Data","HIV_estimates_from_1990-to-present.xlsx")

dfs <- path %>% 
  excel_sheets() %>% 
  set_names() %>% 
  map(read_excel, path = path)

dfs
```


Ok, let's clear our workspace because now we are going to load the data we will use for merging and appending.

## Merging data

```{r}
#load data
df_Jupiter_POS <- read_csv("https://raw.githubusercontent.com/USAID-OHA-SI/coRps/master/2020-05-29/FY20Q1_Jupiter_POS.csv")
```
  
  
```{r}
df_Jupiter_mechs <- read_csv("https://raw.githubusercontent.com/USAID-OHA-SI/coRps/master/2020-05-29/FY20_Jupiter_mechs.csv")
```
  
```{r}
df_Jupiter_NEW <- read_csv("https://raw.githubusercontent.com/USAID-OHA-SI/coRps/master/2020-05-29/FY20Q1_NEW.csv")
```

Inspect the POS and mechs data

```{r}
glimpse(df_Jupiter_POS)
glimpse(df_Jupiter_mechs)
```

May also help to print so you can see the full contents of each

```{r}
print(df_Jupiter_POS)
```

```{r}
print(df_Jupiter_mechs)
```

We want to merge these so that we have the partner and mech names in our POS dataset

```{r}
df_Jupiter_POS_LJ <- df_Jupiter_POS %>% 

  
  
```

Let's check out the originals vs. our results

```{r}
print(df_Jupiter_POS)
print(df_Jupiter_mechs)
print(df_Jupiter_POS_LJ)
```


What if we did it the other way around - starting with the mech table

```{r}
df_Jupiter_mechs_LJ<-df_Jupiter_mechs %>% 

  
  
```

Wow let's look at the originals vs. our two results

```{r}
print(df_Jupiter_POS)
print(df_Jupiter_mechs)
print(df_Jupiter_POS_LJ)
print(df_Jupiter_mechs_LJ)
```

The left_join is one of the "mutating joins" because it adds new variables to one data frame from the matching observations in the other. The other mutating joings are:
- right_join
- inner_join
- full_join

The other types of joins are "filtering joins" because they filter the data based on matches in the tables instead of adding variables to a table. They are:
- semi_join
- anti_join

Let's try one out. Say you wanted a list of partners that reported HTS_TST_POS in FY20Q1 in Jupiter. You don't care about the POS values, you just want to know what partners reported. You can use a semi-join.

Semi join:

```{r}
df_Jupiter_mechs_POS<-df_Jupiter_mechs %>% 
  
  
  
```


Check the results - did it filter the mech list to only those who reported POS?

```{r}
print(df_Jupiter_mechs_POS)
print(df_Jupiter_POS)

```

An anti- join works similary but will just keep the rows of the first table where there are NOT matching values in the second. Let's try it on the same data we used for semi_join.

Anti join to see which Jupiter partners did NOT report POS in FY20Q1

```{r}
df_mechs_nonPOS<-df_Jupiter_mechs %>% 
  
  
```


Check the results

```{r}
print(df_Jupiter_POS)
print(df_mechs_nonPOS)
```


## Appending data

Now we are going to work on appending data sets. Let's say you had Jupiter's POS results for FY20Q1, and had TX_NEW results in a different data set. But you want them combined into a single table.

```{r}
#check the format of POS & NEW data sets
glimpse(df_Jupiter_POS)
glimpse(df_Jupiter_NEW)
```


Let's append or "stack" these on top of each other

```{r}
df_Jupiter_combined <- 
  
  
  
```


See what that looks like

```{r}
print(df_Jupiter_combined)
```
